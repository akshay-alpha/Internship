{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "676f7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the libraries required\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "#to ignore DeprecationWarning warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf09c0",
   "metadata": {},
   "source": [
    "### 1. Python program to scrape data for “Data Analyst” Job position in “Bangalore” location.\n",
    "\n",
    "Scraping data of first 10 job-title, job-location, company_name, experience_required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bda1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#finding elements for job search: job and location\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "#searching the jobs by clicking search buttion\n",
    "search_btn = driver.find_element_by_xpath('//div[@class=\"search-btn\"]/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18e0c89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of lists are:\n",
      "  10 10 10 10\n",
      "\n",
      " The Dataframe of scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring -Data Analyst, Business Analyst, MIS An...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst/ Data Analyst- Capital Market...</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst for HANA Platform</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Intel</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>NetraDyne Technology India Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Assistant/deputy Manager - Geo-spatial Data An...</td>\n",
       "      <td>Gurgaon/Gurugram, bangalore</td>\n",
       "      <td>Maruti Suzuki India</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Slice</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Hiring -Data Analyst, Business Analyst, MIS An...   \n",
       "1  Business Analyst/ Data Analyst- Capital Market...   \n",
       "2                                       Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5                                Senior Data Analyst   \n",
       "6              Senior Data Analyst for HANA Platform   \n",
       "7                                       Data Analyst   \n",
       "8  Assistant/deputy Manager - Geo-spatial Data An...   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                  Job Location                                Company Name  \\\n",
       "0          Bangalore/Bengaluru                                    Flipkart   \n",
       "1    Pune, Bangalore/Bengaluru                                     Genpact   \n",
       "2          Bangalore/Bengaluru     GlaxoSmithKline Pharmaceuticals Limited   \n",
       "3          Bangalore/Bengaluru                          Schneider Electric   \n",
       "4          Bangalore/Bengaluru     GlaxoSmithKline Pharmaceuticals Limited   \n",
       "5          Bangalore/Bengaluru                                    Flipkart   \n",
       "6          Bangalore/Bengaluru                                       Intel   \n",
       "7          Bangalore/Bengaluru  NetraDyne Technology India Private Limited   \n",
       "8  Gurgaon/Gurugram, bangalore                         Maruti Suzuki India   \n",
       "9          Bangalore/Bengaluru                                       Slice   \n",
       "\n",
       "  Experience Required  \n",
       "0             1-6 Yrs  \n",
       "1            7-12 Yrs  \n",
       "2             3-8 Yrs  \n",
       "3             2-5 Yrs  \n",
       "4             3-8 Yrs  \n",
       "5             3-7 Yrs  \n",
       "6            5-10 Yrs  \n",
       "7             2-5 Yrs  \n",
       "8             3-5 Yrs  \n",
       "9             0-2 Yrs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us start scraping the data of each elements and storing them in empty lists.\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_names=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "#extracting all job title tags first\n",
    "titles_tag = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(titles_tag)):\n",
    "    if i <10:\n",
    "        title= titles_tag[i].text\n",
    "        job_title.append(title)\n",
    "\n",
    "#extracting all job location tags \n",
    "location_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(location_tags)):\n",
    "    if i <10:\n",
    "        location= location_tags[i].text\n",
    "        job_location.append(location)\n",
    "\n",
    "\n",
    "#extracting all company_name tags\n",
    "companyname_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(companyname_tags)):\n",
    "    if i <10:\n",
    "        name= companyname_tags[i].text\n",
    "        company_names.append(name)\n",
    "\n",
    "\n",
    "#extracting  experience_required tags\n",
    "experience_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(experience_tags)):\n",
    "    if i <10:\n",
    "        experience = experience_tags[i].text\n",
    "        experience_required.append(experience)\n",
    "    \n",
    "\n",
    "#checking the length of all lists\n",
    "print(\"The length of lists are:\\n \",len(job_title),len(job_location),len(company_names),len(experience_required))\n",
    "\n",
    "\n",
    "#converting all the list into dataframe\n",
    "print(\"\\n The Dataframe of scraped data:\")\n",
    "Jobs = pd.DataFrame({'Job Title':job_title, 'Job Location':job_location, 'Company Name': company_names, 'Experience Required': experience_required})\n",
    "\n",
    "\n",
    "Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612422d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ff5be6",
   "metadata": {},
   "source": [
    "### 2. Python program to scrape data for “Data Scientist” Job position in “Bangalore” location \n",
    "\n",
    "Scraping data of first 10 job-title, job-location, company_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c34b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#finding elements for job search: job and location\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_loc = driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "#searching the jobs by clicking search buttion\n",
    "search_btn = driver.find_element_by_xpath('//div[@class=\"search-btn\"]/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52986b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of lists are: 10 10 10\n",
      "The Dataframe of scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deputy Manager - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>HDFC LIFE INSURANCE COMPANY LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tcs Hiring For Azure ML Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Engineer - AIML - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Unisys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior data scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Compile Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cognitive/AI Senior Data Scientist</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead/Senior Data Scientist (NLP)</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Samya.AI A FRACTAL Entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Superior Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thoucentric Technology Pvt ltd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job Title  \\\n",
       "0       Data Scientist: Advanced Analytics   \n",
       "1          Deputy Manager - Data Scientist   \n",
       "2   Tcs Hiring For Azure ML Data Scientist   \n",
       "3  Senior Engineer - AIML - Data Scientist   \n",
       "4                    Senior data scientist   \n",
       "5       Cognitive/AI Senior Data Scientist   \n",
       "6                    Senior Data Scientist   \n",
       "7         Lead/Senior Data Scientist (NLP)   \n",
       "8                           Data scientist   \n",
       "9                           Data Scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                                Bengaluru/Bangalore   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bengaluru/Bangalore   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7            Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                          Company Name  \n",
       "0               IBM India Pvt. Limited  \n",
       "1  HDFC LIFE INSURANCE COMPANY LIMITED  \n",
       "2       Tata Consultancy Services Ltd.  \n",
       "3                               Unisys  \n",
       "4                          Compile Inc  \n",
       "5               IBM India Pvt. Limited  \n",
       "6                                 Visa  \n",
       "7            Samya.AI A FRACTAL Entity  \n",
       "8                       Superior Group  \n",
       "9       Thoucentric Technology Pvt ltd  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us start scraping the data of each elements and storing them in empty lists.\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_names=[] \n",
    "\n",
    "\n",
    "#extracting all job title tags first\n",
    "titles_tag = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(titles_tag)):\n",
    "    if i <10:\n",
    "        title= titles_tag[i].text\n",
    "        job_title.append(title)\n",
    "\n",
    "#extracting all job location tags \n",
    "location_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(location_tags)):\n",
    "    if i <10:\n",
    "        location= location_tags[i].text\n",
    "        job_location.append(location)\n",
    "\n",
    "\n",
    "#extracting all company_name tags\n",
    "companyname_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(companyname_tags)):\n",
    "    if i <10:\n",
    "        name= companyname_tags[i].text\n",
    "        company_names.append(name)\n",
    "    \n",
    "\n",
    "#checking the length of all lists\n",
    "print(\"The length of lists are:\",len(job_title), len(job_location),len(company_names))\n",
    "\n",
    "#converting all the list into dataframe\n",
    "print(\"The Dataframe of scraped data:\")\n",
    "Jobs = pd.DataFrame({'Job Title':job_title, 'Job Location':job_location, 'Company Name': company_names})\n",
    "\n",
    "\n",
    "Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569abe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6901c2b1",
   "metadata": {},
   "source": [
    "### 3. Python program to scrape data for “Data Scientist” designation for first 10 job results using location=Delhi/NCR and salary filter in https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5ff6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#finding elements for job search: job and location\n",
    "search_job = driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "#searching the jobs by clicking search buttion\n",
    "search_btn = driver.find_element_by_xpath('//div[@class=\"search-btn\"]/button')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74d4249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters: location = Delhi \n",
    "location_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9000ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters: salary\n",
    "salary_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e292c276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of lists are: 10 10 10 10\n",
      "The Dataframe of scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist- Predictive Modelling</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Bangalore/Bengaluru, ...</td>\n",
       "      <td>Emmess technologies private Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, New Delhi, Faridabad, Gurgaon/Gurugram,...</td>\n",
       "      <td>LG Electronics India Pvt. Ltd.</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist | Senior Data Scientist</td>\n",
       "      <td>Delhi / NCR, DelhiNCR</td>\n",
       "      <td>4bell Technology</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Manager - Forecasting data scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Title  \\\n",
       "0                        Senior Data Scientist   \n",
       "1                        Senior Data Scientist   \n",
       "2                    Hiring For Data Scientist   \n",
       "3         Data Scientist- Predictive Modelling   \n",
       "4                               Data Scientist   \n",
       "5                          Lead Data Scientist   \n",
       "6       Data Scientist | Senior Data Scientist   \n",
       "7           Data Scientist: Advanced Analytics   \n",
       "8                           Sr. Data Scientist   \n",
       "9  Senior Manager - Forecasting data scientist   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0             Pune, Bangalore/Bengaluru, Delhi / NCR   \n",
       "1  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...   \n",
       "2  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "3  Noida, Gurgaon/Gurugram, Bangalore/Bengaluru, ...   \n",
       "4  Noida, New Delhi, Faridabad, Gurgaon/Gurugram,...   \n",
       "5  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "6                              Delhi / NCR, DelhiNCR   \n",
       "7                                        Delhi / NCR   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                           Company Name Experience Required  \n",
       "0                                 Wipro             4-9 Yrs  \n",
       "1                                 Wipro            5-10 Yrs  \n",
       "2        Tata Consultancy Services Ltd.             4-9 Yrs  \n",
       "3   Emmess technologies private Limited             3-8 Yrs  \n",
       "4        LG Electronics India Pvt. Ltd.             0-2 Yrs  \n",
       "5  TransOrg Solutions Services (P) Ltd.             4-9 Yrs  \n",
       "6                      4bell Technology            6-11 Yrs  \n",
       "7                IBM India Pvt. Limited            5-10 Yrs  \n",
       "8                               Genpact             4-9 Yrs  \n",
       "9                               Genpact            5-10 Yrs  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us start scraping the data of each elements and storing them in empty lists.\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_names=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "#extracting all job title tags first\n",
    "titles_tag = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(titles_tag)):\n",
    "    if i <10:\n",
    "        title= titles_tag[i].text\n",
    "        job_title.append(title)\n",
    "\n",
    "#extracting all job location tags \n",
    "location_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(location_tags)):\n",
    "    if i <10:\n",
    "        location= location_tags[i].text\n",
    "        job_location.append(location)\n",
    "\n",
    "\n",
    "#extracting all company_name tags\n",
    "companyname_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(companyname_tags)):\n",
    "    if i <10:\n",
    "        name= companyname_tags[i].text\n",
    "        company_names.append(name)\n",
    "\n",
    "\n",
    "#extracting  experience_required tags\n",
    "experience_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "#extracting all the text data from tags fetched\n",
    "for i in range(len(experience_tags)):\n",
    "    if i <10:\n",
    "        experience = experience_tags[i].text\n",
    "        experience_required.append(experience)\n",
    "    \n",
    "\n",
    "#checking the length of all lists\n",
    "print(\"The length of lists are:\",len(job_title), len(job_location),len(company_names),len(experience_required))\n",
    "\n",
    "#converting all the list into dataframe\n",
    "print(\"The Dataframe of scraped data:\")\n",
    "Jobs = pd.DataFrame({'Job Title':job_title, 'Job Location':job_location, 'Company Name': company_names, 'Experience Required': experience_required})\n",
    "\n",
    "\n",
    "Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c74eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "058097a9",
   "metadata": {},
   "source": [
    "### 4.  Python program to scrape data of first 100 sunglasses listings on https://www.flipkart.com/  \n",
    "Scraping Brand, Product Description,Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec5739de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver= webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "#click the cancel button for pop up.\n",
    "cancel_btn = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "cancel_btn.click()\n",
    "\n",
    "#finding elements for product search: \n",
    "product_search= driver.find_element_by_class_name(\"_3704LK\")\n",
    "product_search.send_keys(\"sunglasses\")\n",
    "\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4432ac56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of lists are: 100 100 100\n",
      "The Dataframe of scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Av...</td>\n",
       "      <td>₹295,85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Aviator Sunglasses (53)</td>\n",
       "      <td>₹999,50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹188,85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹212,86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248,90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹759,62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹319,84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹383,80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹474,78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection, Riding Glasses, Mirrored Wayfar...</td>\n",
       "      <td>₹999,50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description  \\\n",
       "0           GANSTA  UV Protection, Night Vision, Riding Glasses Av...   \n",
       "1    VINCENT CHASE  by Lenskart UV Protection Aviator Sunglasses (53)   \n",
       "2             SRPM             UV Protection Wayfarer Sunglasses (56)   \n",
       "3           PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "4        Elligator                UV Protection Round Sunglasses (54)   \n",
       "..             ...                                                ...   \n",
       "95       ROYAL SON  UV Protection, Gradient Rectangular Sunglasses...   \n",
       "96      PHENOMENAL  UV Protection Retro Square Sunglasses (Free Size)   \n",
       "97  ROZZETTA CRAFT  by Lenskart Polarized, UV Protection Wayfarer ...   \n",
       "98  ROZZETTA CRAFT              UV Protection Aviator Sunglasses (55)   \n",
       "99   VINCENT CHASE  UV Protection, Riding Glasses, Mirrored Wayfar...   \n",
       "\n",
       "           Price  \n",
       "0   ₹295,85% off  \n",
       "1   ₹999,50% off  \n",
       "2   ₹188,85% off  \n",
       "3   ₹212,86% off  \n",
       "4   ₹248,90% off  \n",
       "..           ...  \n",
       "95  ₹759,62% off  \n",
       "96  ₹319,84% off  \n",
       "97  ₹383,80% off  \n",
       "98  ₹474,78% off  \n",
       "99  ₹999,50% off  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping data\n",
    "Brand=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "\n",
    "#fetching data from multiple pages iterating over page numbers\n",
    "a = driver.current_url\n",
    "\n",
    "for page in range(1,4,1):\n",
    "    driv = a +'page='+str(page)\n",
    "    \n",
    "        \n",
    "    #extracting all brand tags \n",
    "    brand_tags = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "    #extracting text data from the tags\n",
    "    for i in range(len(brand_tags)):\n",
    "        if page == 3:\n",
    "            if i <20:\n",
    "                brand_name= brand_tags[i].text\n",
    "                Brand.append(brand_name)\n",
    "        else:\n",
    "            brand_name= brand_tags[i].text\n",
    "            Brand.append(brand_name)\n",
    "\n",
    "    #extracting all Product description tags \n",
    "    prod_desc_tags = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "\n",
    "    #extracting text data from the tags\n",
    "    for i in range(len(prod_desc_tags)):\n",
    "        if page == 3:\n",
    "            if i <22:\n",
    "                description = prod_desc_tags[i].text\n",
    "                Product_Description.append(description)\n",
    "        else:\n",
    "            description = prod_desc_tags[i].text\n",
    "            Product_Description.append(description)\n",
    "            \n",
    "    #selecting price and percentage discount values  of different class\n",
    "    price_tags = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    percent_tags = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in range(len(price_tags)):\n",
    "        if page == 3:\n",
    "            if i <20:\n",
    "                cost = price_tags[i].text+','+percent_tags[i].text\n",
    "                Price.append(cost)\n",
    "        else:\n",
    "            cost = price_tags[i].text+','+percent_tags[i].text\n",
    "            Price.append(cost)\n",
    "\n",
    "\n",
    "print(\"The length of lists are:\",len(Brand), len(Product_Description),len(Price))\n",
    "\n",
    "print(\"The Dataframe of scraped data:\")\n",
    "df = pd.DataFrame({'Brand':Brand,'Product Description':Product_Description,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc081aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "197a577b",
   "metadata": {},
   "source": [
    "### 5. Python program to scrape 100 reviews data from flipkart.com for iphone11 phone. \n",
    "Scrape 1. Rating, 2. Review_summary 3. Full review of first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f06c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver =  webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "#to scrape the data from given link\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-%20earpods-power%02adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC%20TSVZAXUHGREPBFGI&marketplace\")\n",
    "\n",
    "#first fetch all reviews to scrape first 100 review\n",
    "all_review = driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffc65fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of each list are: (100, 100, 100)\n",
      "\n",
      " The dataframe of Rating, Review Summary and Full Review is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5            Fabulous!   \n",
       "96      5        Great product   \n",
       "97      4          Good choice   \n",
       "98      5    Worth every penny   \n",
       "99      5   Highly recommended   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first iOS phone. I am very happy wi...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  So far it’s been an AMAZING experience coming ...  \n",
       "98  i11 is worthy to buy, too much happy with the ...  \n",
       "99  iphone 11 is a very good phone to buy only if ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists to store all the scraped data:\n",
    "\n",
    "rating = []\n",
    "Review_summary=[]\n",
    "Full_review=[]\n",
    "\n",
    "a = driver.current_url\n",
    "\n",
    "for page in range(1,11,1):\n",
    "    driv = a+\"&page=\"+str(page)    \n",
    "    \n",
    "    #fetching all rating tags first\n",
    "    rating_tags = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "\n",
    "    #extracting text data from the tags\n",
    "    for i in range(len(rating_tags)):\n",
    "        if page==10:\n",
    "            value = rating_tags[i].text\n",
    "            rating.append(value)\n",
    "        else:\n",
    "            value = rating_tags[i].text\n",
    "            rating.append(value)\n",
    "\n",
    "    #fetching all summary tags\n",
    "    summary_tags = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "\n",
    "    #extracting text data from the tags and storing in list\n",
    "    for i in range(len(summary_tags)):\n",
    "        if page==10:\n",
    "            value = summary_tags[i].text\n",
    "            Review_summary.append(value)\n",
    "        else:\n",
    "            value = summary_tags[i].text\n",
    "            Review_summary.append(value)\n",
    "\n",
    "        #fetching all full review tags\n",
    "    full_review_tags = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "    #extracting text data from the tags and storing in list\n",
    "    for i in range(len(full_review_tags)):\n",
    "        if page==10:\n",
    "            value = full_review_tags[i].text\n",
    "            Full_review.append(value)\n",
    "        else:\n",
    "            value = full_review_tags[i].text\n",
    "            Full_review.append(value)\n",
    "\n",
    "print(\"The length of each list are:\",(len(rating), len(Review_summary), len(Full_review)))\n",
    "        \n",
    "print(\"\\n The dataframe of Rating, Review Summary and Full Review is:\")\n",
    "df = pd.DataFrame({'Rating':rating,'Review Summary': Review_summary, 'Full Review': Full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02381568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e02e39f",
   "metadata": {},
   "source": [
    "### 6. Scrape data for first 100 sneakers you find when you visit https://www.flipkart.com/ and search for “sneakers” in the search field. \n",
    "Scrape 1. Brand 2. Product Description 3. Price  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25e7daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver= webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.flipkart.com/')\n",
    "\n",
    "#click the cancel button for pop up.\n",
    "cancel_btn = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "cancel_btn.click()\n",
    "\n",
    "#finding elements for product search: \n",
    "product_search= driver.find_element_by_class_name(\"_3704LK\")\n",
    "product_search.send_keys(\"sneakers\")\n",
    "\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90c4f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of all lists : 100 100 100\n",
      "The Dataframe of scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRK</td>\n",
       "      <td>SRK Men's stylish shoes Sneakers For Men</td>\n",
       "      <td>₹549,54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹423,57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹590,40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sports Running Shoes Sneakers For Men</td>\n",
       "      <td>₹322,35% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹536,66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SHOEFLY</td>\n",
       "      <td>Running Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹649,56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹173,65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Clymb</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,999,50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ganpati traders</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499,75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Smash v2 SL one8 Sneakers For Men</td>\n",
       "      <td>₹379,62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                Product Description  \\\n",
       "0               SRK           SRK Men's stylish shoes Sneakers For Men   \n",
       "1             BIRDE                                   Sneakers For Men   \n",
       "2          RapidBox                                   Sneakers For Men   \n",
       "3             BIRDE              Sports Running Shoes Sneakers For Men   \n",
       "4            Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...   \n",
       "..              ...                                                ...   \n",
       "95          SHOEFLY             Running Shoes For Men Sneakers For Men   \n",
       "96        SCATCHITE                          Sneakers Sneakers For Men   \n",
       "97            Clymb                                   Sneakers For Men   \n",
       "98  ganpati traders                                   Sneakers For Men   \n",
       "99             PUMA                  Smash v2 SL one8 Sneakers For Men   \n",
       "\n",
       "             Price  \n",
       "0     ₹549,54% off  \n",
       "1     ₹423,57% off  \n",
       "2     ₹590,40% off  \n",
       "3     ₹322,35% off  \n",
       "4     ₹536,66% off  \n",
       "..             ...  \n",
       "95    ₹649,56% off  \n",
       "96    ₹173,65% off  \n",
       "97  ₹1,999,50% off  \n",
       "98    ₹499,75% off  \n",
       "99    ₹379,62% off  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping data\n",
    "Brand=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "\n",
    "#fetching data from multiple pages iterating over page numbers\n",
    "a = driver.current_url\n",
    "\n",
    "for page in range(1,4,1):\n",
    "    driv = a +'page='+str(page)\n",
    "    \n",
    "        \n",
    "    #extracting all brand tags \n",
    "    brand_tags = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "    #extracting text data from the tags\n",
    "    for i in range(len(brand_tags)):\n",
    "        if page == 3:\n",
    "            if i <20:\n",
    "                brand_name= brand_tags[i].text\n",
    "                Brand.append(brand_name)\n",
    "        else:\n",
    "            brand_name= brand_tags[i].text\n",
    "            Brand.append(brand_name)\n",
    "\n",
    "    #extracting all Product description tags \n",
    "    prod_desc_tags = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\" or @class=\"IRpwTa _2-ICcC\"]')\n",
    "\n",
    "    #extracting text data from the tags\n",
    "    for i in range(len(prod_desc_tags)):\n",
    "        if page == 3:\n",
    "            if i <20:\n",
    "                description = prod_desc_tags[i].text\n",
    "                Product_Description.append(description)\n",
    "        else:\n",
    "            description = prod_desc_tags[i].text\n",
    "            Product_Description.append(description)\n",
    "            \n",
    "    \n",
    "    #selecting price and percentage discount values  of different class\n",
    "    price_tags = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    percent_tags = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    \n",
    "    for i in range(len(percent_tags)):\n",
    "        if page == 3:\n",
    "            if i <22:\n",
    "                cost = price_tags[i].text+','+percent_tags[i].text\n",
    "                Price.append(cost)\n",
    "        else:\n",
    "            cost = price_tags[i].text+','+percent_tags[i].text\n",
    "            Price.append(cost)\n",
    "\n",
    "print(\"The length of all lists :\",len(Brand), len(Product_Description), len(Price))\n",
    "\n",
    "print(\"The Dataframe of scraped data:\")\n",
    "df = pd.DataFrame({'Brand':Brand,'Product Description':Product_Description,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8fbf82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1b482f4",
   "metadata": {},
   "source": [
    "### 7. Python program to visit the https://www.myntra.com/shoes link apply the  Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, and scrape First 100 shoes data. \n",
    "Scrape 1. Brand 2. Product Description 3. Price  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b48251df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver= webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "\n",
    "#filters: Price (As “Rs. 6649 to Rs. 13099” is not available, applied nearest filter)\n",
    "Price_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "Price_filter.click()\n",
    "\n",
    "#filters: Color\n",
    "Color_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "Color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78d98c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of all lists : 100 100 100\n",
      "\n",
      " The Dataframe of scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Shoe Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Street Style Store</td>\n",
       "      <td>Women Suede High-Top Flat Boots</td>\n",
       "      <td>Women Suede High-Top Flat Boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eego Italy</td>\n",
       "      <td>Men Trekking Shoes</td>\n",
       "      <td>Men Trekking Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Revolution 5 Running Shoes</td>\n",
       "      <td>Men Revolution 5 Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Drift Cat 8 Sneakers</td>\n",
       "      <td>Unisex Drift Cat 8 Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ZAPATOZ</td>\n",
       "      <td>Women Walking Shoes</td>\n",
       "      <td>Women Walking Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Fire Run IDP Sneakers</td>\n",
       "      <td>Men Fire Run IDP Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ASIAN</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fentacia</td>\n",
       "      <td>Men Lightweight Flat Boots</td>\n",
       "      <td>Men Lightweight Flat Boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Glarus Running Shoes</td>\n",
       "      <td>Men Glarus Running Shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Brand                 Shoe Description  \\\n",
       "0   Street Style Store  Women Suede High-Top Flat Boots   \n",
       "1           Eego Italy               Men Trekking Shoes   \n",
       "2                 Nike   Men Revolution 5 Running Shoes   \n",
       "3             Red Tape                Men Walking Shoes   \n",
       "4      PUMA Motorsport      Unisex Drift Cat 8 Sneakers   \n",
       "..                 ...                              ...   \n",
       "95             ZAPATOZ              Women Walking Shoes   \n",
       "96                Puma        Men Fire Run IDP Sneakers   \n",
       "97               ASIAN                Men Running Shoes   \n",
       "98            Fentacia       Men Lightweight Flat Boots   \n",
       "99              ADIDAS         Men Glarus Running Shoes   \n",
       "\n",
       "                              Price  \n",
       "0   Women Suede High-Top Flat Boots  \n",
       "1                Men Trekking Shoes  \n",
       "2    Men Revolution 5 Running Shoes  \n",
       "3                 Men Walking Shoes  \n",
       "4       Unisex Drift Cat 8 Sneakers  \n",
       "..                              ...  \n",
       "95              Women Walking Shoes  \n",
       "96        Men Fire Run IDP Sneakers  \n",
       "97                Men Running Shoes  \n",
       "98       Men Lightweight Flat Boots  \n",
       "99         Men Glarus Running Shoes  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping data\n",
    "Brand=[]\n",
    "Shoe_Description=[]\n",
    "Price=[]\n",
    "\n",
    "#fetching data from multiple pages iterating over page numbers\n",
    "a = driver.current_url\n",
    "\n",
    "for page in range(1,3,1):\n",
    "    driv = a +'p='+str(page)\n",
    "\n",
    "    #extracting all brand tags \n",
    "    brand_tags = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "\n",
    "    #extracting text data from the tags\n",
    "    for i in range(len(brand_tags)):\n",
    "        brand_name= brand_tags[i].text\n",
    "        Brand.append(brand_name)\n",
    "       \n",
    "    #extracting all description tags \n",
    "    shoe_desc_tags = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "\n",
    "    #extracting text data from the tags\n",
    "    for i in range(len(shoe_desc_tags)):\n",
    "        description = shoe_desc_tags[i].text\n",
    "        Shoe_Description.append(description)\n",
    "        \n",
    "    #extracting all price tags \n",
    "    price_tags = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "\n",
    "    #extracting text data from the tags\n",
    "    for i in range(len(price_tags)):\n",
    "        value = shoe_desc_tags[i].text\n",
    "        Price.append(value)\n",
    "        \n",
    "print(\"The length of all lists :\",len(Brand), len(Shoe_Description), len(Price))\n",
    "\n",
    "print(\"\\n The Dataframe of scraped data:\")\n",
    "df = pd.DataFrame({'Brand':Brand,'Shoe Description':Shoe_Description,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c776c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c9da09a",
   "metadata": {},
   "source": [
    "### 8. Python program to scrape data of Laptops inthe https://www.amazon.in/ link apply the  Price filter to “ “Intel Core i7” and “Intel Core i9”, and scrape First 10 laptop data. \n",
    "Scrape 1. Title 2. Rating 3. Price  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4bd86168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver= webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "#finding elements for Laptop search: \n",
    "product_search= driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "product_search.send_keys(\"Laptops\")\n",
    "\n",
    "#click search button\n",
    "search_btn = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e2edecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters: Intel Core i7 and Intel Core i9 \n",
    "intel_i7_i9 = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[1]/li[10]/span/a/div/label/i\")\n",
    "intel_i7_i9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24a3cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data\n",
    "Title=[]\n",
    "\n",
    "#extracting all title tags\n",
    "title_tags= driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "\n",
    "#extracting text data from the tags\n",
    "for i in range(len(title_tags)):\n",
    "    if i <10:\n",
    "        value = title_tags[i].text\n",
    "        Title.append(value)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82489789",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price=[]\n",
    "#extracting all price tags\n",
    "price_tags= driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "\n",
    "#extracting text data from the tags\n",
    "for i in range(len(price_tags)):\n",
    "    if i <10:\n",
    "        value = price_tags[i].text\n",
    "        Price.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81a687d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "hrefs=[]\n",
    "#extracting all rating tags   \n",
    "link_tags = driver.find_elements_by_xpath('//a[@class=\"a-link-normal a-text-normal\"]')\n",
    "for link in range(len(link_tags)):\n",
    "    href = link_tags[link].get_attribute('href')\n",
    "    hrefs.append(href)\n",
    "\n",
    "for i in range(len(hrefs)):\n",
    "    if i <10:\n",
    "        driver.get(hrefs[i])\n",
    "        rating = driver.find_element_by_xpath('//span[@class=\"a-size-base a-nowrap\"]/span')\n",
    "        Rating.append(rating.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ca1f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of all lists : t 10 r 10 p 10\n",
      "\n",
      " The Dataframe of scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel i7 Core 13.3 inche...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Pro QHD+ IPS Anti Glare Display In...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>72,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" Full ...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>97,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel i7 Core 13.3 inche...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>90,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Gaming(2021) 10th Gen Intel Core i...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acer Swift 5 Intel i7 11th Gen 14 inches Ultra...</td>\n",
       "      <td>3.6 out of 5</td>\n",
       "      <td>91,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Rating   Price\n",
       "0  Fujitsu UH-X 11th Gen Intel i7 Core 13.3 inche...  4.3 out of 5  92,990\n",
       "1  Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...    4 out of 5  89,990\n",
       "2  Mi Notebook Pro QHD+ IPS Anti Glare Display In...  4.3 out of 5  72,999\n",
       "3  Lenovo Yoga 7 11th Gen Intel Core i7 14\" Full ...  4.3 out of 5  97,490\n",
       "4  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.2 out of 5  49,990\n",
       "5  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...  4.3 out of 5  84,990\n",
       "6  Fujitsu UH-X 11th Gen Intel i7 Core 13.3 inche...  4.3 out of 5  92,990\n",
       "7  Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...  4.3 out of 5  90,990\n",
       "8  HP Pavilion Gaming(2021) 10th Gen Intel Core i...  4.1 out of 5  86,990\n",
       "9  Acer Swift 5 Intel i7 11th Gen 14 inches Ultra...  3.6 out of 5  91,990"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking length of all lists\n",
    "print(\"The length of all lists :\",'t',len(Title), 'r',len(Rating),'p',len(Price))\n",
    "\n",
    "print(\"\\n The Dataframe of scraped data:\")\n",
    "df = pd.DataFrame({'Title':Title,'Rating':Rating,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c135b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21d195de",
   "metadata": {},
   "source": [
    "### 9. Python program to scrape data for first 10 job results for Data Scientist Designation in Noida location from https://www.ambitionbox.com/. \n",
    "\n",
    "Scarpe company name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b065ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "job_tab = driver.find_element_by_xpath('//a[@class=\"link jobs\"]')\n",
    "job_tab.click()\n",
    "\n",
    "#finding elements for job search: job and location\n",
    "search_job = driver.find_element_by_xpath('//input[@class=\"input tt-input\"]')\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"ab_btn search-btn round\"]/span')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b346685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//div[@title=\"Location\"]').click()\n",
    "\n",
    "loc = driver.find_element_by_id('location_Noida').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7b5c56de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of all lists : 10 10 10\n",
      "\n",
      " The Dataframe of scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Job updated</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Electronics India Pvt. Ltd.</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NTT Data Business Solutions Pvt Ltd</td>\n",
       "      <td>13d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Steria India Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zyoin</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Company Names Job updated Rating\n",
       "0       LG Electronics India Pvt. Ltd.      5d ago    4.1\n",
       "1        GENPACT India Private Limited     12d ago    4.0\n",
       "2        GENPACT India Private Limited     12d ago    4.0\n",
       "3  NTT Data Business Solutions Pvt Ltd     13d ago    3.8\n",
       "4        GENPACT India Private Limited     14d ago    4.0\n",
       "5                             GI Group      6d ago    4.0\n",
       "6                             GI Group      6d ago    4.0\n",
       "7                             GI Group     10d ago    4.0\n",
       "8                     Steria India Ltd    1mon ago    4.1\n",
       "9                                Zyoin      7d ago    4.1"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_names = []\n",
    "No_of_days =[]\n",
    "Rating = []\n",
    "\n",
    "#extract all the company tags\n",
    "company_tags = driver.find_elements_by_xpath('//p[@class=\"company body-medium\"]')\n",
    "\n",
    "#extracting text data from the tags\n",
    "for i in range(len(company_tags)):\n",
    "    if i < 10:\n",
    "        name = company_tags[i].text\n",
    "        Company_names.append(name)\n",
    "\n",
    "\n",
    "#extract all the number of days tags\n",
    "days_tags = driver.find_elements_by_xpath('//span[@class=\"body-small-l\"]')\n",
    "\n",
    "\n",
    "#extracting text data from the tags\n",
    "for i in range(len(days_tags)):\n",
    "    if i < 19:\n",
    "        name = days_tags[i].text\n",
    "        if name == 'via naukri.com' or name == 'via iimjobs.com':\n",
    "            continue \n",
    "        else:\n",
    "            No_of_days.append(name)\n",
    "\n",
    "\n",
    "#extract all the rating tags\n",
    "rating_tags = driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "\n",
    "\n",
    "#extracting text data from the tags\n",
    "for i in range(len(rating_tags)):\n",
    "    if i < 10:\n",
    "        name = rating_tags[i].text\n",
    "        Rating.append(name)\n",
    "        \n",
    "        \n",
    "#checking length of all lists\n",
    "print(\"The length of all lists :\",len(Company_names), len(No_of_days), len(Rating))\n",
    "\n",
    "print(\"\\n The Dataframe of scraped data:\")\n",
    "df = pd.DataFrame({'Company Names':Company_names,'Job updated': No_of_days,'Rating':Rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb1310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9844b656",
   "metadata": {},
   "source": [
    "### 10. Python program to scrape the salary data for Data Scientist designation from https://www.ambitionbox.com/ \n",
    "\n",
    "Scrape Company name, Number of salaries, Average salary, Min salary, Max Salary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "738f7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the webdriver\n",
    "driver = webdriver.Chrome(r\"C:/Users/atoranga/Documents/chromedriver.exe\")\n",
    "\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "\n",
    "job_tab = driver.find_element_by_xpath('//a[@title=\"Company Salaries\"]')\n",
    "job_tab.click()\n",
    "\n",
    "#finding elements for salary comparision: jobs\n",
    "search_job = driver.find_element_by_xpath('//input[@class=\"tt-input\"]')\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_btn = driver.find_element_by_xpath('//i[@class=\"icon-search\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "96638101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of all lists : 10 10 10 10 10\n",
      "\n",
      " The Dataframe of scraped data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Salary updated</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tekion</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 23.3L</td>\n",
       "      <td>[['₹ 14.0L'</td>\n",
       "      <td>[['₹ 32.0L'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>based on 218 salaries</td>\n",
       "      <td>₹ 22.4L</td>\n",
       "      <td>'₹ 12.0L'</td>\n",
       "      <td>'₹ 45.0L'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 21.9L</td>\n",
       "      <td>'₹ 16.0L'</td>\n",
       "      <td>'₹ 30.0L'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>based on 53 salaries</td>\n",
       "      <td>₹ 20.6L</td>\n",
       "      <td>'₹ 7.0L'</td>\n",
       "      <td>'₹ 30.0L'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>based on 80 salaries</td>\n",
       "      <td>₹ 19.1L</td>\n",
       "      <td>'₹ 8.0L'</td>\n",
       "      <td>'₹ 40.0L'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arcesium</td>\n",
       "      <td>based on 35 salaries</td>\n",
       "      <td>₹ 18.4L</td>\n",
       "      <td>'₹ 12.0L'</td>\n",
       "      <td>'₹ 30.0L'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Servicenow Software Development India</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>₹ 18.2L</td>\n",
       "      <td>'₹ 12.0L'</td>\n",
       "      <td>'₹ 25.0L'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ServiceNow</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>₹ 18.2L</td>\n",
       "      <td>'₹ 12.7L'</td>\n",
       "      <td>'₹ 23.0L'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 77 salaries</td>\n",
       "      <td>₹ 17.9L</td>\n",
       "      <td>'₹ 10.0L'</td>\n",
       "      <td>'₹ 32.0L'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "      <td>₹ 17.6L</td>\n",
       "      <td>'₹ 12.0L']]</td>\n",
       "      <td>'₹ 23.0L']]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Company Names         Salary updated  \\\n",
       "0                                 Tekion   based on 10 salaries   \n",
       "1                  Microsoft Corporation  based on 218 salaries   \n",
       "2                          Goldman Sachs   based on 11 salaries   \n",
       "3                               Flipkart   based on 53 salaries   \n",
       "4                                 Amazon   based on 80 salaries   \n",
       "5                               Arcesium   based on 35 salaries   \n",
       "6  Servicenow Software Development India   based on 27 salaries   \n",
       "7                             ServiceNow   based on 15 salaries   \n",
       "8                                Walmart   based on 77 salaries   \n",
       "9                                 PayPal   based on 12 salaries   \n",
       "\n",
       "  Average Salary Minimum Salary Maximum Salary  \n",
       "0        ₹ 23.3L    [['₹ 14.0L'    [['₹ 32.0L'  \n",
       "1        ₹ 22.4L      '₹ 12.0L'      '₹ 45.0L'  \n",
       "2        ₹ 21.9L      '₹ 16.0L'      '₹ 30.0L'  \n",
       "3        ₹ 20.6L       '₹ 7.0L'      '₹ 30.0L'  \n",
       "4        ₹ 19.1L       '₹ 8.0L'      '₹ 40.0L'  \n",
       "5        ₹ 18.4L      '₹ 12.0L'      '₹ 30.0L'  \n",
       "6        ₹ 18.2L      '₹ 12.0L'      '₹ 25.0L'  \n",
       "7        ₹ 18.2L      '₹ 12.7L'      '₹ 23.0L'  \n",
       "8        ₹ 17.9L      '₹ 10.0L'      '₹ 32.0L'  \n",
       "9        ₹ 17.6L    '₹ 12.0L']]    '₹ 23.0L']]  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_names = []\n",
    "No_of_sal =[]\n",
    "Average_sal = []\n",
    "Sal=[]\n",
    "Min_sal=[]\n",
    "Max_sal = []\n",
    "\n",
    "#extract all the company tags\n",
    "name_tags = driver.find_elements_by_xpath('//div[@class=\"name\"]')\n",
    "\n",
    "#extracting text data from the tags\n",
    "for i in range(len(name_tags)):\n",
    "    if i < 10:\n",
    "        name = name_tags[i].text.split('\\n')[0]\n",
    "        Company_names.append(name)\n",
    "\n",
    "#extract all the company tags\n",
    "no_sal_tags = driver.find_elements_by_xpath('//div[@class=\"name\"]')\n",
    "\n",
    "#extracting text data from the tags\n",
    "for i in range(len(no_sal_tags)):\n",
    "    if i < 10:\n",
    "        val = no_sal_tags[i].text.split('\\n')[1]\n",
    "        No_of_sal.append(val)\n",
    "\n",
    "#extract all the Average tags\n",
    "avg_sal_tags = driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "\n",
    "#extracting average sal text data from the tags\n",
    "for i in range(len(avg_sal_tags)):\n",
    "    if i < 10:\n",
    "        avg = avg_sal_tags[i].text    \n",
    "        Average_sal.append(avg)\n",
    "\n",
    "\n",
    "        \n",
    "#extract all the sal tags\n",
    "sal_tags = driver.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "\n",
    "#extracting text data of min and max salary from the tags using logic,\n",
    "for i in range(len(sal_tags)):\n",
    "    if i <20:\n",
    "        sal = sal_tags[i].text\n",
    "        Sal.append(sal)\n",
    "        \n",
    "Min_sal.append(Sal[0::2])\n",
    "Min_sal=str(Min_sal).split(',')\n",
    "Max_sal.append(Sal[1::2])\n",
    "Max_sal=str(Max_sal).split(',')\n",
    "    \n",
    "\n",
    "    \n",
    "#checking length of all lists\n",
    "print(\"The length of all lists :\",len(Company_names),len(No_of_sal), len(Average_sal),len(Min_sal), len(Max_sal))\n",
    "\n",
    "print(\"\\n The Dataframe of scraped data:\")\n",
    "df = pd.DataFrame({'Company Names':Company_names,'Salary updated': No_of_sal,'Average Salary':Average_sal,'Minimum Salary':Min_sal,'Maximum Salary':Max_sal})\n",
    "df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0027c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f6aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
